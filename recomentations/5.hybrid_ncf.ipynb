{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f2e45f-f23b-4fd2-8ae2-900fe3196bd5",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering \n",
    "\n",
    "* Goal: Build a Neural Collaborative Filtering (NCF)-based hybrid recommender system with Pairwise Ranking \n",
    "* Use both user and item features\n",
    "* Use text embedding of product title, descriprion and features\n",
    "* Model seems to be overfitting, needs some work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6980d6-dc50-4cc0-80ce-8f778d889199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from aux.feature_engineering import calculate_rolling_stats\n",
    "from aux.train_test_split import (\n",
    "    global_temporal_split,\n",
    "    temporal_split_users_in_both_sets,\n",
    "    temporal_split_users_with_cold_start,\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee533acd-b51e-4140-8fbf-0e7787803a5b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9220d61b-9ad4-4055-bd6d-8915be7a9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reviews = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True)\n",
    "df_reviews = dataset_reviews[\"full\"].to_pandas()\n",
    "\n",
    "dataset_items = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_All_Beauty\", split=\"full\", trust_remote_code=True)\n",
    "df_items = dataset_items.to_pandas()\n",
    "\n",
    "# filter out users with low ammount of reviews for now - look at the cold start problem later\n",
    "min_ammount_reviews = 5\n",
    "user_review_counts = df_reviews.groupby('user_id').size()\n",
    "users_with_min_reviews = user_review_counts[user_review_counts >= min_ammount_reviews].index\n",
    "df_reviews_filtered = df_reviews[df_reviews['user_id'].isin(users_with_min_reviews)]\n",
    "\n",
    "df = pd.merge(df_reviews_filtered, df_items, on='parent_asin', how='left', suffixes=('_review', '_item'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ff5b5-1d1f-478a-8005-426b8ef7fd01",
   "metadata": {},
   "source": [
    "# Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a92bc0e-9e15-4119-a235-7007d247885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_purchase'] = df.verified_purchase.astype('int')\n",
    "df['store'] = df['store'].fillna('UNKNOWN')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df['year'] = df['timestamp'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e5bdf-dc4a-43a8-9153-8270fcc70146",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d4de84-c237-40c0-9f9b-f6411df4ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_rolling_stats(df, 'user_id')  \n",
    "df = calculate_rolling_stats(df, 'parent_asin')  \n",
    "df = df.sort_values(by='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e23a7-01bc-461e-83e7-4e240d35018f",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "261a6744-ba32-4fff-b061-61d84d7dc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features\n",
    "user_review_features = ['user_id', 'rolling_avg_rating_user', 'rolling_review_count_user', 'helpful_vote', 'verified_purchase', 'year']\n",
    "product_features = ['parent_asin', 'average_rating', 'rolling_avg_rating_product', 'rolling_review_count_product', 'rating_number']\n",
    "categoricals = ['main_category', 'store']\n",
    "target = 'rating'\n",
    "\n",
    "train_test_split_features =  ['timestamp']\n",
    "\n",
    "columns = train_test_split_features + user_review_features + product_features + categoricals  + [target]\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a27b68b-945f-4011-8e64-98359eec5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_numeric_cols = [\n",
    "    \"rolling_avg_rating_user\",\n",
    "    \"rolling_review_count_user\",\n",
    "    \"helpful_vote\",\n",
    "    \"verified_purchase\",  \n",
    "    \"year\"\n",
    "]\n",
    "\n",
    "item_numeric_cols = [\n",
    "    \"average_rating\",\n",
    "    \"rolling_avg_rating_product\",\n",
    "    \"rolling_review_count_product\",\n",
    "    \"rating_number\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f401a2-9a54-492c-9694-fc870d0c992a",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73129e34-7374-4e6c-a595-a3e031807057",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = global_temporal_split(df, split_ratio=0.8, exclude_cold_start_users=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1d526-88a0-4ad4-8f2a-ccaf30cbfee1",
   "metadata": {},
   "source": [
    "# Encode User and Item ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4124f87-7f4b-4680-8d15-d418f9341a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# fit encoders on training data only\n",
    "user_encoder.fit(train_df['user_id'])\n",
    "item_encoder.fit(train_df['parent_asin'])  # assuming parent_asin is your item_id\n",
    "\n",
    "# transform training data\n",
    "train_user_ids = user_encoder.transform(train_df['user_id'])\n",
    "train_item_ids = item_encoder.transform(train_df['parent_asin'])\n",
    "\n",
    "# for test set, handle new users and items\n",
    "test_user_ids = []\n",
    "test_item_ids = []\n",
    "\n",
    "for user_id, item_id in zip(test_df['user_id'], test_df['parent_asin']):\n",
    "    if user_id in user_encoder.classes_:\n",
    "        test_user_ids.append(user_encoder.transform([user_id])[0])\n",
    "    else:\n",
    "        test_user_ids.append(len(user_encoder.classes_))\n",
    "    \n",
    "    if item_id in item_encoder.classes_:\n",
    "        test_item_ids.append(item_encoder.transform([item_id])[0])\n",
    "    else:\n",
    "        test_item_ids.append(len(item_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677f5b2-5dc6-46ec-b215-15ecdf27b4b2",
   "metadata": {},
   "source": [
    "# Load product embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "451af84d-6531-4b92-92cb-2f46372cebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = np.load('train_embeddings.npy')\n",
    "test_embeddings = np.load('test_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ed9ac-3498-4bd6-9c4a-486ccec6133c",
   "metadata": {},
   "source": [
    "# User, Item and Product Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a846bb3-8bd9-4b12-a4a0-d8280b8914b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_train = train_df[user_numeric_cols]\n",
    "user_data_test = test_df[user_numeric_cols]\n",
    "\n",
    "# process item features and embeddings\n",
    "base_item_train = train_df[item_numeric_cols]\n",
    "base_item_test = test_df[item_numeric_cols]\n",
    "\n",
    "train_emb_df = pd.DataFrame(\n",
    "    train_embeddings, \n",
    "    columns=[f'emb_{i}' for i in range(train_embeddings.shape[1])]\n",
    ")\n",
    "test_emb_df = pd.DataFrame(\n",
    "    test_embeddings, \n",
    "    columns=[f'emb_{i}' for i in range(test_embeddings.shape[1])]\n",
    ")\n",
    "\n",
    "item_data_train = pd.concat([base_item_train, train_emb_df], axis=1)\n",
    "item_data_test = pd.concat([base_item_test, test_emb_df], axis=1)\n",
    "\n",
    "train_ratings = train_df[target]\n",
    "test_ratings = test_df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fd173675-865d-4203-9028-201a8e30242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "## Scale user features\n",
    "#user_scaler = StandardScaler()\n",
    "#user_data_train_scaled = user_scaler.fit_transform(user_data_train)\n",
    "#user_data_test_scaled = user_scaler.transform(user_data_test)\n",
    "#\n",
    "#item_scaler = StandardScaler()\n",
    "#base_item_train_scaled = item_scaler.fit_transform(base_item_train)\n",
    "#base_item_test_scaled = item_scaler.transform(base_item_test)\n",
    "#\n",
    "## Convert scaled user data back to DataFrame\n",
    "#    user_data_train_scaled, \n",
    "#    columns=user_data_train.columns, \n",
    "#    index=user_data_train.index\n",
    "#)\n",
    "#user_data_test = pd.DataFrame(\n",
    "#    user_data_test_scaled, \n",
    "#    columns=user_data_test.columns, \n",
    "#    index=user_data_test.index\n",
    "#)\n",
    "#\n",
    "#item_data_train = pd.concat([\n",
    "#    pd.DataFrame(base_item_train_scaled, columns=base_item_train.columns, index=base_item_train.index),\n",
    "#    train_emb_df\n",
    "#], axis=1)\n",
    "#\n",
    "#item_data_test = pd.concat([\n",
    "#    pd.DataFrame(base_item_test_scaled, columns=base_item_test.columns, index=base_item_test.index),\n",
    "#    test_emb_df\n",
    "#], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7c117837-c6b6-4d64-82dc-fa97fc63925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rolling_avg_rating_user</th>\n",
       "      <th>rolling_review_count_user</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936376</td>\n",
       "      <td>-0.545577</td>\n",
       "      <td>4.964564</td>\n",
       "      <td>-0.724747</td>\n",
       "      <td>-7.82991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.278780</td>\n",
       "      <td>-0.545577</td>\n",
       "      <td>7.562062</td>\n",
       "      <td>-0.724747</td>\n",
       "      <td>-7.82991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.936376</td>\n",
       "      <td>-0.486283</td>\n",
       "      <td>0.029319</td>\n",
       "      <td>-0.724747</td>\n",
       "      <td>-7.82991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.936376</td>\n",
       "      <td>-0.426990</td>\n",
       "      <td>0.289068</td>\n",
       "      <td>-0.724747</td>\n",
       "      <td>-7.32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.936376</td>\n",
       "      <td>-0.545577</td>\n",
       "      <td>1.068318</td>\n",
       "      <td>1.379793</td>\n",
       "      <td>-7.32000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rolling_avg_rating_user  rolling_review_count_user  helpful_vote  \\\n",
       "0                 0.936376                  -0.545577      4.964564   \n",
       "1                -0.278780                  -0.545577      7.562062   \n",
       "2                 0.936376                  -0.486283      0.029319   \n",
       "3                 0.936376                  -0.426990      0.289068   \n",
       "4                 0.936376                  -0.545577      1.068318   \n",
       "\n",
       "   verified_purchase     year  \n",
       "0          -0.724747 -7.82991  \n",
       "1          -0.724747 -7.82991  \n",
       "2          -0.724747 -7.82991  \n",
       "3          -0.724747 -7.32000  \n",
       "4           1.379793 -7.32000  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799bad7-4eb2-4239-9203-164e4d333a24",
   "metadata": {},
   "source": [
    "# Build Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2acfdb7d-814f-49e2-a35a-ba28271181d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingDataset(Dataset):\n",
    "    def __init__(self, user_data, item_data, ratings, user_ids, item_ids, num_negative=1):\n",
    "        #print(\"\\nDataset initialization:\")\n",
    "        #print(f\"Raw user_data shape: {user_data.shape}\")\n",
    "        #print(f\"Raw item_data shape: {item_data.shape}\")\n",
    "        \n",
    "        self.user_data = torch.FloatTensor(user_data.values)\n",
    "        self.item_data = torch.FloatTensor(item_data.values)\n",
    "        \n",
    "        #print(f\"After conversion to tensor:\")\n",
    "        #print(f\"self.user_data shape: {self.user_data.shape}\")\n",
    "        #print(f\"self.item_data shape: {self.item_data.shape}\")\n",
    "        \n",
    "        self.user_ids = torch.LongTensor(user_ids)\n",
    "        self.item_ids = torch.LongTensor(item_ids)\n",
    "        self.ratings = ratings.values if hasattr(ratings, 'values') else ratings\n",
    "        \n",
    "        # create pairs\n",
    "        self.pairs = []\n",
    "        unique_users = np.unique(user_ids)\n",
    "        \n",
    "        for user_idx in unique_users:\n",
    "            # indices of ratings given by this user\n",
    "            user_indices = np.where(user_ids == user_idx)[0]\n",
    "            user_ratings = self.ratings[user_indices]\n",
    "            \n",
    "            # create positive pairs\n",
    "            for i in range(len(user_indices)):\n",
    "                for j in range(i + 1, len(user_indices)):\n",
    "                    if user_ratings[i] > user_ratings[j]:\n",
    "                        self.pairs.append((user_idx, user_indices[i], user_indices[j]))\n",
    "                    elif user_ratings[i] < user_ratings[j]:\n",
    "                        self.pairs.append((user_idx, user_indices[j], user_indices[i]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_idx, pos_item_idx, neg_item_idx = self.pairs[idx]\n",
    "        #print(\"\\nBatch item shapes:\")\n",
    "        #print(f\"Item data shape: {self.item_data.shape}\")\n",
    "        #print(f\"Single item features shape: {self.item_data[pos_item_idx].shape}\")\n",
    "        return {\n",
    "            'user_id': self.user_ids[user_idx],\n",
    "            'user_features': self.user_data[user_idx],\n",
    "            'pos_item_id': self.item_ids[pos_item_idx],\n",
    "            'pos_item_features': self.item_data[pos_item_idx],\n",
    "            'neg_item_id': self.item_ids[neg_item_idx],\n",
    "            'neg_item_features': self.item_data[neg_item_idx],\n",
    "            'pos_rating': self.ratings[pos_item_idx],\n",
    "            'neg_rating': self.ratings[neg_item_idx]\n",
    "        }\n",
    "\n",
    "class EvaluationDataset(Dataset):\n",
    "    def __init__(self, user_data, item_data, ratings, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        user_data: shape [n_users, user_feature_dim]\n",
    "        item_data: shape [n_items, item_feature_dim]\n",
    "        \n",
    "        user_ids, item_ids: arrays of length N, each element is an integer ID\n",
    "          in [0..n_users-1], [0..n_items-1] respectively (after label-encoding).\n",
    "        \"\"\"\n",
    "        self.user_data = torch.FloatTensor(user_data.values)\n",
    "        self.item_data = torch.FloatTensor(item_data.values)\n",
    "        \n",
    "        self.user_ids = torch.LongTensor(user_ids)\n",
    "        self.item_ids = torch.LongTensor(item_ids)\n",
    "        \n",
    "        self.ratings = (\n",
    "            ratings.values if hasattr(ratings, \"values\") else ratings\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return {\n",
    "            \"user_id\": self.user_ids[idx],\n",
    "            \"user_features\": self.user_data[idx],  \n",
    "            \"item_id\": self.item_ids[idx],\n",
    "            \"item_features\": self.item_data[idx],  \n",
    "            \"rating\": self.ratings[idx],\n",
    "        }\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3273dcd8-512b-43f3-a21e-8c74745be7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dataset creation:\n",
      "user_data_train shape: (11987, 5)\n",
      "item_data_train shape: (11987, 388)\n",
      "user_data_test shape: (2997, 5)\n",
      "item_data_test shape: (2997, 388)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before dataset creation:\")\n",
    "print(f\"user_data_train shape: {user_data_train.shape}\")\n",
    "print(f\"item_data_train shape: {item_data_train.shape}\")\n",
    "print(f\"user_data_test shape: {user_data_test.shape}\")\n",
    "print(f\"item_data_test shape: {item_data_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9c46569e-0ecc-415f-a431-00b19972a0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11987,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_item_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6e0cdab0-3d5d-4983-856f-41bd73996ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11987,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a61fdfa9-0ea3-4113-beca-2cbbf1c69c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RankingDataset(\n",
    "    user_data=user_data_train,  \n",
    "    item_data=item_data_train, \n",
    "    ratings=train_ratings,\n",
    "    user_ids=train_user_ids,\n",
    "    item_ids=train_item_ids\n",
    ")\n",
    "# to train\n",
    "test_dataset = RankingDataset(\n",
    "    user_data=user_data_test,\n",
    "    item_data=item_data_test,\n",
    "    ratings=test_ratings,\n",
    "    user_ids=test_user_ids,\n",
    "    item_ids=test_item_ids\n",
    ")\n",
    "# for eval has to have a different structure\n",
    "evaluation_dataset = EvaluationDataset(\n",
    "    user_data=user_data_test,\n",
    "    item_data=item_data_test,\n",
    "    ratings=test_ratings,\n",
    "    user_ids=test_user_ids,\n",
    "    item_ids=test_item_ids\n",
    ")    \n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1c4172af-fd81-47f2-9101-69d8fc4bc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingNCF(nn.Module):\n",
    "    def __init__(self, user_features, item_features, hidden_layers=[8]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_linear = nn.Linear(user_features, hidden_layers[0])\n",
    "        self.user_bn = nn.BatchNorm1d(hidden_layers[0])\n",
    "        self.user_dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.item_linear = nn.Linear(item_features, hidden_layers[0])\n",
    "        self.item_bn = nn.BatchNorm1d(hidden_layers[0])\n",
    "        self.item_dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.score = nn.Sequential(\n",
    "            nn.Linear(hidden_layers[0] * 2, hidden_layers[0]),\n",
    "            nn.BatchNorm1d(hidden_layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_layers[0], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_features, item_features):\n",
    "        # User tower with residual\n",
    "        user_out = self.user_linear(user_features)\n",
    "        user_out = self.user_bn(user_out)\n",
    "        user_out = F.relu(user_out)\n",
    "        user_out = self.user_dropout(user_out) + user_out  # residual connection\n",
    "        \n",
    "        # Item tower with residual\n",
    "        item_out = self.item_linear(item_features)\n",
    "        item_out = self.item_bn(item_out)\n",
    "        item_out = F.relu(item_out)\n",
    "        item_out = self.item_dropout(item_out) + item_out  # residual connection\n",
    "        \n",
    "        combined = torch.cat([user_out, item_out], dim=1)\n",
    "        return self.score(combined).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d544d62-dc29-42d6-87a6-25430a8b16e0",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a64bc1b2-5ff5-45ce-8019-8609aeb7706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def train_ranking_model(model, train_loader, val_loader, epochs=10, lr=0.0005):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.005)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            user_features = batch['user_features'].to(device)\n",
    "            pos_item_features = batch['pos_item_features'].to(device)\n",
    "            neg_item_features = batch['neg_item_features'].to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            pos_scores = model(user_features, pos_item_features)\n",
    "            neg_scores = model(user_features, neg_item_features)\n",
    "            \n",
    "            # BPR loss\n",
    "            loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
    "            #loss = torch.max(torch.zeros_like(pos_scores), 1 - (pos_scores - neg_scores)).mean()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                user_features = batch['user_features'].to(device)\n",
    "                pos_item_features = batch['pos_item_features'].to(device)\n",
    "                neg_item_features = batch['neg_item_features'].to(device)\n",
    "                \n",
    "                pos_scores = model(user_features, pos_item_features)\n",
    "                neg_scores = model(user_features, neg_item_features)\n",
    "                \n",
    "                loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
    "                #loss = torch.max(torch.zeros_like(pos_scores), 1 - (pos_scores - neg_scores)).mean()\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'Training Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "419561df-4b41-496b-ad1f-95ee3e2dfc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RankingNCF(\n",
    "    user_features=user_data_train.shape[1],  # 5\n",
    "    item_features=item_data_train.shape[1],  # 388\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d5941d79-8b34-46a5-b3a6-3d23378f80b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15:\n",
      "Training Loss: 0.6965\n",
      "Validation Loss: 0.6776\n",
      "--------------------------------------------------\n",
      "Epoch 2/15:\n",
      "Training Loss: 0.6708\n",
      "Validation Loss: 0.6953\n",
      "--------------------------------------------------\n",
      "Epoch 3/15:\n",
      "Training Loss: 0.5433\n",
      "Validation Loss: 0.6651\n",
      "--------------------------------------------------\n",
      "Epoch 4/15:\n",
      "Training Loss: 0.3820\n",
      "Validation Loss: 0.6750\n",
      "--------------------------------------------------\n",
      "Epoch 5/15:\n",
      "Training Loss: 0.2750\n",
      "Validation Loss: 0.6712\n",
      "--------------------------------------------------\n",
      "Epoch 6/15:\n",
      "Training Loss: 0.2213\n",
      "Validation Loss: 0.6651\n",
      "--------------------------------------------------\n",
      "Epoch 7/15:\n",
      "Training Loss: 0.1936\n",
      "Validation Loss: 0.6664\n",
      "--------------------------------------------------\n",
      "Epoch 8/15:\n",
      "Training Loss: 0.1725\n",
      "Validation Loss: 0.7117\n",
      "--------------------------------------------------\n",
      "Epoch 9/15:\n",
      "Training Loss: 0.1651\n",
      "Validation Loss: 0.7395\n",
      "--------------------------------------------------\n",
      "Epoch 10/15:\n",
      "Training Loss: 0.1525\n",
      "Validation Loss: 0.7300\n",
      "--------------------------------------------------\n",
      "Epoch 11/15:\n",
      "Training Loss: 0.1549\n",
      "Validation Loss: 0.7050\n",
      "--------------------------------------------------\n",
      "Epoch 12/15:\n",
      "Training Loss: 0.1459\n",
      "Validation Loss: 0.6072\n",
      "--------------------------------------------------\n",
      "Epoch 13/15:\n",
      "Training Loss: 0.1375\n",
      "Validation Loss: 0.6869\n",
      "--------------------------------------------------\n",
      "Epoch 14/15:\n",
      "Training Loss: 0.1399\n",
      "Validation Loss: 0.6331\n",
      "--------------------------------------------------\n",
      "Epoch 15/15:\n",
      "Training Loss: 0.1392\n",
      "Validation Loss: 0.5840\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = train_ranking_model(model, train_loader, test_loader,  epochs=15)\n",
    "model.load_state_dict(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f53b5-021b-4846-a90a-f51fbfb1c0c6",
   "metadata": {},
   "source": [
    "# Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c98eb056-31b6-4f1d-9795-8f0d9b841019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationDataset(Dataset):\n",
    "    def __init__(self, user_data, item_data, ratings, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        user_data: shape [n_users, user_feature_dim]\n",
    "        item_data: shape [n_items, item_feature_dim]\n",
    "        \n",
    "        user_ids, item_ids: arrays of length N, each element is an integer ID\n",
    "          in [0..n_users-1], [0..n_items-1] respectively (after label-encoding).\n",
    "        \"\"\"\n",
    "        self.user_data = torch.FloatTensor(user_data.values)\n",
    "        self.item_data = torch.FloatTensor(item_data.values)\n",
    "        \n",
    "        self.user_ids = torch.LongTensor(user_ids)\n",
    "        self.item_ids = torch.LongTensor(item_ids)\n",
    "        \n",
    "        self.ratings = (\n",
    "            ratings.values if hasattr(ratings, \"values\") else ratings\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return {\n",
    "            \"user_id\": self.user_ids[idx],\n",
    "            \"user_data\": self.user_data[idx],  \n",
    "            \"item_id\": self.item_ids[idx],\n",
    "            \"item_data\": self.item_data[idx],  \n",
    "            \"rating\": self.ratings[idx],\n",
    "        }\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0e9cc4c9-ab76-4379-8e8e-a1eefe16abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset = EvaluationDataset(\n",
    "    user_data=user_data_test,\n",
    "    item_data=item_data_test,\n",
    "    ratings=test_ratings,\n",
    "    user_ids=test_user_ids,\n",
    "    item_ids=test_item_ids\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3ff3da1e-388d-4737-a88e-85df44222d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2568,  0.7479, -0.2778,  ..., -0.0630,  0.0079,  0.0536],\n",
       "        [ 1.8829,  0.7479, -0.6557,  ..., -0.0766, -0.0121, -0.0057],\n",
       "        [ 0.9795,  0.7479, -0.6557,  ..., -0.0645, -0.1007, -0.0193],\n",
       "        ...,\n",
       "        [ 0.6181, -0.8336,  0.8556,  ..., -0.0486,  0.0793,  0.0202],\n",
       "        [ 0.6181, -0.7348,  0.4778,  ..., -0.0486,  0.0793,  0.0202],\n",
       "        [ 0.6181, -0.5700,  0.1000,  ..., -0.0486,  0.0793,  0.0202]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset.item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bbfbdd27-2b27-47f1-bc17-7994e8cb2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_user_ids = []\n",
    "all_item_ids = []\n",
    "all_ratings = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in evaluation_dataset:\n",
    "        user_ids = batch['user_id'].to(device).unsqueeze(0) \n",
    "        user_feats = batch['user_data'].to(device).unsqueeze(0) \n",
    "        item_ids = batch['item_id'].to(device).unsqueeze(0) \n",
    "        item_feats = batch['item_data'].to(device).unsqueeze(0) \n",
    "\n",
    "        # predict scores\n",
    "        scores = model(user_feats, item_feats)\n",
    "        \n",
    "        all_user_ids.extend(user_ids.cpu().numpy())\n",
    "        all_item_ids.extend(item_ids.cpu().numpy())\n",
    "        all_ratings.append(batch[\"rating\"])\n",
    "        all_preds.append(scores.cpu().numpy())\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"user_id\": all_user_ids,\n",
    "    \"item_id\": all_item_ids,\n",
    "    \"rating\": all_ratings,\n",
    "    \"predicted_score\": all_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c10d3a32-1125-47ac-bf92-c1a5d9cdc6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG@10 across all users with mora than 1 rating (381, 0.625615763546798% of the test set): 0.9785\n"
     ]
    }
   ],
   "source": [
    "ndcg_scores = []\n",
    "num_users = 0\n",
    "for user_id in test_df['user_id'].unique():\n",
    "    true_relevance = test_df[test_df['user_id'] == user_id][target].tolist()\n",
    "    predicted_scores = test_df[test_df['user_id'] == user_id]['predicted_score'].tolist()\n",
    "    if len(predicted_scores) > 1:\n",
    "        user_ndcg = ndcg_score([true_relevance], [predicted_scores], k=10)\n",
    "        ndcg_scores.append(user_ndcg)\n",
    "        num_users += 1\n",
    "\n",
    "average_ndcg = np.mean(ndcg_scores)\n",
    "print(f\"Average NDCG@10 across all users with mora than 1 rating ({num_users}, {num_users/test_df.user_id.unique().shape[0]}% of the test set): {average_ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "124da872-b560-4611-a962-ad58b687ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision@10': 0.23415435139573013, 'recall@10': 0.8499832743629435}\n"
     ]
    }
   ],
   "source": [
    "def precision_recall_at_k(group, k=10):\n",
    "    # sort by predicted_score descending\n",
    "    group_sorted = group.sort_values(\"predicted_score\", ascending=False)\n",
    "    \n",
    "    top_k = group_sorted.head(k)\n",
    "    \n",
    "    # number of relevant items in the top K\n",
    "    relevant_in_top_k = top_k[\"relevant\"].sum()\n",
    "    \n",
    "    # total relevant items for this user\n",
    "    total_relevant = group[\"relevant\"].sum()\n",
    "    \n",
    "    precision_k = relevant_in_top_k / k\n",
    "    recall_k = relevant_in_top_k / total_relevant if total_relevant > 0 else 0.0\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"precision@{}\".format(k): precision_k,\n",
    "        \"recall@{}\".format(k): recall_k\n",
    "    })\n",
    "\n",
    "def compute_precision_recall_at_k(df, user_col=\"user_id\", k=10):\n",
    "    \"\"\" \n",
    "    Compute mean precision@K and recall@K across all users. \n",
    "    \"\"\"\n",
    "    metrics_df = (\n",
    "        df\n",
    "        .groupby(user_col)\n",
    "        [df.columns]\n",
    "        .apply(lambda g: precision_recall_at_k(g, k))\n",
    "    )\n",
    "\n",
    "    return metrics_df.mean().to_dict()\n",
    "\n",
    "\n",
    "test_df[\"relevant\"] = (test_df[\"rating\"] >= 4).astype(int)\n",
    "\n",
    "test_df_sorted = (\n",
    "    test_df\n",
    "    .groupby(\"user_id\", group_keys=False)\n",
    "    [['user_id', 'relevant', 'predicted_score']] \n",
    "    .apply(lambda df: df.sort_values(\"predicted_score\", ascending=False))\n",
    ")\n",
    "\n",
    "metrics_k10 = compute_precision_recall_at_k(test_df_sorted, user_col=\"user_id\", k=10)\n",
    "print(metrics_k10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fbff5-a05b-470c-9960-204750981a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
